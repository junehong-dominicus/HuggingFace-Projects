# ğŸ¤— Hugging Face Model Playground

Welcome to the Hugging Face Model Playground! This repository is dedicated to studying, experimenting with, and benchmarking transformer models using the Hugging Face ecosystem.

## ğŸ“Œ Objectives

- Explore various model architectures (e.g., BERT, GPT, T5, Vision Transformers)
- Run inference and fine-tuning examples
- Benchmark performance across tasks and hardware
- Document optimization techniques (quantization, mixed precision, etc.)
- Share deployment-ready scripts and notebooks

## ğŸ§° Repository Structure

```
HuggingFace-Projects/
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks for experiments
â”œâ”€â”€ scripts/                # Python scripts for training/inference
â”œâ”€â”€ benchmarks/             # Performance metrics and comparisons
â”œâ”€â”€ datasets/               # Custom or downloaded datasets
â”œâ”€â”€ docs/                   # Documentation and guides
â””â”€â”€ README.md               # This file
```

## ğŸš€ Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/junehong-dominicus/HuggingFace-Projects.git
   cd HuggingFace-Projects
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Run your first notebook:
   ```bash
   jupyter notebook notebooks/text-generation-gpt2.ipynb
   ```

## ğŸ§ª Model Categories

- **Text Generation**: GPT-2, LLaMA, Gemma
- **Embeddings**: BERT, RoBERTa
- **Multimodal**: BLIP-2, CLIP
- **Seq2Seq**: T5, BART

## ğŸ“Š Benchmarks

| Model      | Task              | Accuracy | Inference Time |
|------------|-------------------|----------|----------------|
| BERT       | Sentiment Analysis| 92.3%    | 0.12s/sample   |
| GPT-2      | Text Generation   | N/A      | 0.45s/sample   |

## ğŸ“š Resources

- [Hugging Face Documentation](https://huggingface.co/docs)
- [Transformers Library](https://github.com/huggingface/transformers)
- [Datasets Library](https://github.com/huggingface/datasets)

## ğŸ¤ Contributing

Feel free to fork, star, and submit pull requests. Contributions are welcome!

## ğŸ“„ License

This project is licensed under the MIT License.
